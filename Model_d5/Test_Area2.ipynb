{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from seed import set_seed\n",
    "from data_generator import gendata_Linear\n",
    "from data_generator import gendata_Deep\n",
    "set_seed(114)\n",
    "test_data = gendata_Deep(500, 0.5)\n",
    "set_seed(1145)\n",
    "val_data = gendata_Deep(100, 0.5)\n",
    "train_data = gendata_Deep(400, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_val = True\n",
    "n_epoch = 100\n",
    "n_lr = 1e-3\n",
    "n_node = 50\n",
    "n_layer = 2\n",
    "patiences = 10\n",
    "\n",
    "X_train = torch.tensor(train_data['X'], dtype=torch.float32)\n",
    "A_train = torch.tensor(train_data['A'], dtype=torch.float32)\n",
    "R_0_train = torch.tensor(train_data['R'], dtype=torch.float32)\n",
    "logR_0_train = torch.log(R_0_train)\n",
    "#A_tr = (A_train,1-A_train)\n",
    "\n",
    "X_val = torch.tensor(val_data['X'], dtype=torch.float32)\n",
    "A_val = torch.tensor(val_data['A'], dtype=torch.float32)\n",
    "R_0_val = torch.tensor(val_data['R'], dtype=torch.float32)\n",
    "logR_0_val = torch.log(R_0_val)\n",
    "\n",
    "X_test = torch.tensor(test_data['X'], dtype=torch.float32)\n",
    "A_test = torch.tensor(test_data['A'], dtype=torch.float32)\n",
    "R_0_test = torch.tensor(test_data['R'], dtype=torch.float32)\n",
    "logR_0_test = torch.log(R_0_test)\n",
    "# t_nodes = torch.tensor(t_nodes, dtype=torch.float32)\n",
    "# t_fig = torch.tensor(t_fig, dtype=torch.float32)\n",
    "d_X = X_train.size()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_features=d_X , out_features=3, hidden_nodes=n_node, hidden_layers=n_layer, drop_rate=0):\n",
    "        super(DNNModel, self).__init__()\n",
    "        layers = []\n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(in_features, hidden_nodes))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Dropout(drop_rate))\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(torch.nn.Linear(hidden_nodes, hidden_nodes))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(drop_rate))\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_nodes, out_features))\n",
    "        self.linear_relu_stack = torch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = DNNModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=n_lr)\n",
    "\n",
    "# Custom loss function for binary decision: via MSEloss\n",
    "# my_loss = torch.nn.MSELoss(reduction='mean')\n",
    "def my_loss(mu_TX, A, logR):  #mu_TX is 3 dim, A = (1,A) is 3 dim, logR is 1 dim\n",
    "    A1 = torch.ones(A.shape[0])\n",
    "    A1 = A1.unsqueeze(1)\n",
    "    A = torch.cat((A1,A),dim = 1) # add the baseline mu0\n",
    "    mu_TX1 = torch.sum(mu_TX*A, dim = 1)\n",
    "    loss_fun = (logR-mu_TX1)**2  #least square\n",
    "    return loss_fun.mean()\n",
    "\n",
    "\n",
    "    #simultaneously calculate the intrgral for A=0 and A=1 (need to be corrected)\n",
    "\n",
    "\n",
    "# Treat and Untreat\n",
    "A_untreat = torch.zeros(A_test.shape, dtype=torch.float32)\n",
    "A_untreat[:,0]=1   #untreat\n",
    "A_treated = torch.zeros(A_test.shape, dtype=torch.float32)\n",
    "A_treated[:,1]=1   #treated\n",
    "\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 val_loss= 1.422686\n",
      "epoch= 1 val_loss= 1.3716295\n",
      "epoch= 2 val_loss= 1.3203996\n",
      "epoch= 3 val_loss= 1.2691836\n",
      "epoch= 4 val_loss= 1.2171057\n",
      "epoch= 5 val_loss= 1.1645485\n",
      "epoch= 6 val_loss= 1.1113552\n",
      "epoch= 7 val_loss= 1.057157\n",
      "epoch= 8 val_loss= 1.0019766\n",
      "epoch= 9 val_loss= 0.94627136\n",
      "epoch= 10 val_loss= 0.8898612\n",
      "epoch= 11 val_loss= 0.83348274\n",
      "epoch= 12 val_loss= 0.7776851\n",
      "epoch= 13 val_loss= 0.7231549\n",
      "epoch= 14 val_loss= 0.6708809\n",
      "epoch= 15 val_loss= 0.6217648\n",
      "epoch= 16 val_loss= 0.5775416\n",
      "epoch= 17 val_loss= 0.5398294\n",
      "epoch= 18 val_loss= 0.5103374\n",
      "epoch= 19 val_loss= 0.49043941\n",
      "epoch= 20 val_loss= 0.48062503\n",
      "epoch= 21 val_loss= 0.4807231\n",
      "patience_counter = 1\n",
      "epoch= 22 val_loss= 0.48924598\n",
      "patience_counter = 2\n",
      "epoch= 23 val_loss= 0.503352\n",
      "patience_counter = 3\n",
      "epoch= 24 val_loss= 0.51891553\n",
      "patience_counter = 4\n",
      "epoch= 25 val_loss= 0.5316055\n",
      "patience_counter = 5\n",
      "epoch= 26 val_loss= 0.5382284\n",
      "patience_counter = 6\n",
      "epoch= 27 val_loss= 0.5373431\n",
      "patience_counter = 7\n",
      "epoch= 28 val_loss= 0.52912027\n",
      "patience_counter = 8\n",
      "epoch= 29 val_loss= 0.51504135\n",
      "patience_counter = 9\n",
      "epoch= 30 val_loss= 0.49729657\n",
      "patience_counter = 10\n",
      "Early stopping at epoch 31,  validation—loss= 0.49729657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()  # Set model to training mode\n",
    "        \n",
    "    # mu_TX = model(torch.cat((logR_0_train.unsqueeze(1), X_train), dim=1)).squeeze()\n",
    "    mu_TX = model(X_train).squeeze()\n",
    "    # int_exp_g_TX = vectorized_gaussian_quadrature_integral(batch_func_train, torch.zeros_like(R_O_train), R_O_train, n_points=100,A=A_train) # batch_size = 0.8n\n",
    "\n",
    "    loss = my_loss(mu_TX, A_train, logR_0_train)\n",
    "    # print('epoch=', epoch, 'loss=', loss.detach().numpy())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # g_TX_val = model(torch.cat((R_O_val.unsqueeze(1), X_val), dim=1)).squeeze()\n",
    "        mu_TX_val = model(X_val).squeeze()\n",
    "        # int_exp_g_TX_val = vectorized_gaussian_quadrature_integral(batch_func_val, torch.zeros_like(R_O_val), R_O_val, n_points=100,A=A_val) # batch_size = 0.2n\n",
    "        \n",
    "        # val_loss = my_loss(g_TX_val, int_exp_g_TX_val, A_val)\n",
    "        val_loss = my_loss(mu_TX_val, A_val, logR_0_val)\n",
    "        if show_val == True:\n",
    "            print('epoch=', epoch, 'val_loss=', val_loss.detach().numpy())\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()  # Save the best model state\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if show_val == True:\n",
    "            print('patience_counter =', patience_counter)\n",
    "        \n",
    "    if patience_counter >= patiences:\n",
    "        if show_val == True:\n",
    "            print(f'Early stopping at epoch {epoch + 1}, ', 'validation—loss=', val_loss.detach().numpy())\n",
    "        break\n",
    "\n",
    "# Restore best model if needed\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9379, 0.2890, 0.4402],\n",
      "        [0.8536, 0.2639, 0.6871],\n",
      "        [0.6677, 0.2777, 0.4412],\n",
      "        ...,\n",
      "        [0.9023, 0.3251, 0.4768],\n",
      "        [0.7182, 0.2660, 0.4716],\n",
      "        [0.9605, 0.3063, 0.7504]], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "mu_TX_test = model(X_test).squeeze()\n",
    "# print(mu_TX_test)\n",
    "mu_base_test = mu_TX_test[:,0]\n",
    "mu_un_test = mu_TX_test[:,1]\n",
    "mu_tr_test = mu_TX_test[:,2]\n",
    "At1 = torch.ones(A_test.shape[0])\n",
    "At1 = At1.unsqueeze(1)\n",
    "A_untreat = torch.zeros(A_test.shape, dtype=torch.float32)\n",
    "A_untreat[:,0]=1   #untreat\n",
    "A_treated = torch.zeros(A_test.shape, dtype=torch.float32)\n",
    "A_treated[:,1]=1   #treated\n",
    "A_untreat = torch.cat((At1,A_untreat),dim=1)\n",
    "A_treated = torch.cat((At1,A_treated),dim=1)\n",
    "Cmean_untreat = torch.exp(torch.sum(A_untreat*mu_TX_test,dim=1))\n",
    "Cmean_treated = torch.exp(torch.sum(A_treated*mu_TX_test,dim=1))\n",
    "print(mu_TX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import pinv\n",
    "import scipy.optimize as spo\n",
    "from data_generator import gendata_Linear\n",
    "from seed import set_seed\n",
    "set_seed(114)\n",
    "beta = np.array([0,-0.5,0.5,-0.25,0.5])\n",
    "gamma = np.array([0.5,-0.25,0,0.5,-0.25])\n",
    "test_data = gendata_Linear(500, 0.5,beta,gamma)\n",
    "\n",
    "set_seed(1194)\n",
    "val_data = gendata_Linear(400, 0.5,beta,gamma)\n",
    "train_data = gendata_Linear(1600, 0.5,beta,gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999874137376902\n",
      "[-4.10426417e-05 -3.26473845e-04  1.14387192e-04  7.97832423e-04\n",
      "  2.06182755e-04]\n",
      "[-7.26571972e-05  6.27652062e-04 -6.25337711e-05 -4.22235312e-04\n",
      " -4.13108551e-04]\n"
     ]
    }
   ],
   "source": [
    "from log_linear_binary import E_ols_bin\n",
    "resl = E_ols_bin(train_data, val_data, test_data)\n",
    "print(resl['intercept'])\n",
    "print((resl['beta'])-beta)\n",
    "print((resl['gamma'])-gamma)\n",
    "Cmean_R_X_treated = resl['Cmean_R_X_treated']\n",
    "Cmean_R_X_untreat = resl['Cmean_R_X_untreat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from optITR import optITR_lin_bin\n",
    "itr = optITR_lin_bin(test_data,Cmean_R_X_treated, Cmean_R_X_untreat, beta,gamma)\n",
    "print(itr['mis_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999376071690771\n",
      "[-0.          0.00089461 -0.00082154  0.00075583 -0.00078075]\n",
      "[-0.00069768  0.00070852 -0.         -0.00062871  0.00067701]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from numpy.linalg import inv\n",
    "# from numpy.linalg import pinv\n",
    "# import scipy.optimize as spo\n",
    "from data_generator import gendata_Linear\n",
    "from seed import set_seed\n",
    "from log_linear_binary import E_lasso_bin\n",
    "from optITR import optITR_lin_bin\n",
    "set_seed(114)\n",
    "beta = np.array([0,-0.5,0.5,-0.25,0.5])\n",
    "gamma = np.array([0.5,-0.25,0,0.5,-0.25])\n",
    "test_data = gendata_Linear(500, 0.5,beta,gamma)\n",
    "\n",
    "set_seed(1194)\n",
    "val_data = gendata_Linear(100, 0.5,beta,gamma)\n",
    "train_data = gendata_Linear(400, 0.5,beta,gamma)\n",
    "\n",
    "reslasso = E_lasso_bin(train_data, val_data, test_data)\n",
    "print(reslasso['intercept'])\n",
    "print((reslasso['beta'])-beta)\n",
    "print((reslasso['gamma'])-gamma)\n",
    "Cmean_R_X_treated = reslasso['Cmean_R_X_treated']\n",
    "Cmean_R_X_untreat = reslasso['Cmean_R_X_untreat']\n",
    "itr = optITR_lin_bin(test_data,Cmean_R_X_treated, Cmean_R_X_untreat, beta,gamma)\n",
    "print(itr['mis_rate'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
