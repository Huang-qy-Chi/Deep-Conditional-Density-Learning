{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN_iteration\n",
      "epoch= 0 val_loss= 0.63108546\n",
      "epoch= 1 val_loss= 0.6178633\n",
      "epoch= 2 val_loss= 0.6060655\n",
      "epoch= 3 val_loss= 0.59572077\n",
      "epoch= 4 val_loss= 0.58777547\n",
      "epoch= 5 val_loss= 0.5838999\n",
      "epoch= 6 val_loss= 0.5854039\n",
      "patience_counter = 1\n",
      "epoch= 7 val_loss= 0.5899481\n",
      "patience_counter = 2\n",
      "epoch= 8 val_loss= 0.5925016\n",
      "patience_counter = 3\n",
      "epoch= 9 val_loss= 0.59034544\n",
      "patience_counter = 4\n",
      "epoch= 10 val_loss= 0.5844992\n",
      "patience_counter = 5\n",
      "epoch= 11 val_loss= 0.577304\n",
      "epoch= 12 val_loss= 0.57060623\n",
      "epoch= 13 val_loss= 0.5648716\n",
      "epoch= 14 val_loss= 0.5600286\n",
      "epoch= 15 val_loss= 0.5557957\n",
      "epoch= 16 val_loss= 0.552137\n",
      "epoch= 17 val_loss= 0.54920435\n",
      "epoch= 18 val_loss= 0.54733574\n",
      "epoch= 19 val_loss= 0.54722446\n",
      "epoch= 20 val_loss= 0.54849124\n",
      "patience_counter = 1\n",
      "epoch= 21 val_loss= 0.54946554\n",
      "patience_counter = 2\n",
      "epoch= 22 val_loss= 0.54857177\n",
      "patience_counter = 3\n",
      "epoch= 23 val_loss= 0.5450228\n",
      "epoch= 24 val_loss= 0.5399767\n",
      "epoch= 25 val_loss= 0.53526753\n",
      "epoch= 26 val_loss= 0.5323467\n",
      "epoch= 27 val_loss= 0.5317113\n",
      "epoch= 28 val_loss= 0.53191394\n",
      "patience_counter = 1\n",
      "epoch= 29 val_loss= 0.53128916\n",
      "epoch= 30 val_loss= 0.5297588\n",
      "epoch= 31 val_loss= 0.5288951\n",
      "epoch= 32 val_loss= 0.5290253\n",
      "patience_counter = 1\n",
      "epoch= 33 val_loss= 0.52978665\n",
      "patience_counter = 2\n",
      "epoch= 34 val_loss= 0.5302052\n",
      "patience_counter = 3\n",
      "epoch= 35 val_loss= 0.5295874\n",
      "patience_counter = 4\n",
      "epoch= 36 val_loss= 0.52780974\n",
      "epoch= 37 val_loss= 0.5265606\n",
      "epoch= 38 val_loss= 0.527832\n",
      "patience_counter = 1\n",
      "epoch= 39 val_loss= 0.5311356\n",
      "patience_counter = 2\n",
      "epoch= 40 val_loss= 0.5347163\n",
      "patience_counter = 3\n",
      "epoch= 41 val_loss= 0.53625107\n",
      "patience_counter = 4\n",
      "epoch= 42 val_loss= 0.5355973\n",
      "patience_counter = 5\n",
      "epoch= 43 val_loss= 0.5363945\n",
      "patience_counter = 6\n",
      "epoch= 44 val_loss= 0.5412384\n",
      "patience_counter = 7\n",
      "epoch= 45 val_loss= 0.55025244\n",
      "patience_counter = 8\n",
      "epoch= 46 val_loss= 0.5593836\n",
      "patience_counter = 9\n",
      "epoch= 47 val_loss= 0.5637233\n",
      "patience_counter = 10\n",
      "epoch= 48 val_loss= 0.5620682\n",
      "patience_counter = 11\n",
      "epoch= 49 val_loss= 0.56087196\n",
      "patience_counter = 12\n",
      "epoch= 50 val_loss= 0.567022\n",
      "patience_counter = 13\n",
      "epoch= 51 val_loss= 0.58036333\n",
      "patience_counter = 14\n",
      "epoch= 52 val_loss= 0.5921041\n",
      "patience_counter = 15\n",
      "epoch= 53 val_loss= 0.59705675\n",
      "patience_counter = 16\n",
      "epoch= 54 val_loss= 0.60651106\n",
      "patience_counter = 17\n",
      "epoch= 55 val_loss= 0.6241776\n",
      "patience_counter = 18\n",
      "epoch= 56 val_loss= 0.64252365\n",
      "patience_counter = 19\n",
      "epoch= 57 val_loss= 0.66346514\n",
      "patience_counter = 20\n",
      "epoch= 58 val_loss= 0.6888993\n",
      "patience_counter = 21\n",
      "epoch= 59 val_loss= 0.7131742\n",
      "patience_counter = 22\n",
      "epoch= 60 val_loss= 0.73456436\n",
      "patience_counter = 23\n",
      "epoch= 61 val_loss= 0.7635152\n",
      "patience_counter = 24\n",
      "epoch= 62 val_loss= 0.7947593\n",
      "patience_counter = 25\n",
      "epoch= 63 val_loss= 0.8502808\n",
      "patience_counter = 26\n",
      "epoch= 64 val_loss= 0.8408935\n",
      "patience_counter = 27\n",
      "epoch= 65 val_loss= 0.96521765\n",
      "patience_counter = 28\n",
      "epoch= 66 val_loss= 0.8887426\n",
      "patience_counter = 29\n",
      "epoch= 67 val_loss= 1.0753431\n",
      "patience_counter = 30\n",
      "Early stopping at epoch 68,  validationâ€”loss= 1.0753431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mis_rate': np.float64(0.15), 'Regret': np.float64(0.03074835155896105)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as ndm\n",
    "import matplotlib.pyplot as plt\n",
    "from seed import set_seed\n",
    "from data_generator import gendata_Linear\n",
    "from data_generator import gendata_Deep \n",
    "from data_generator import gendata_Deep_mixG \n",
    "import torch\n",
    "from log_hazard_binary import g_dnn_bin\n",
    "from optITR import optITR_deep_bin\n",
    "set_seed(114)\n",
    "# set_seed(1145)\n",
    "patiences = 30\n",
    "n_node = 128\n",
    "n_layer = 2\n",
    "t_nodes = 100\n",
    "t_fig = 50\n",
    "n_lr = 1.2e-3\n",
    "n_epoch = 1000\n",
    "s_k = 0.1*np.arange(100)\n",
    "\n",
    "# beta = np.array([0,-0.5,0.5,-0.25,0.5])\n",
    "# gamma = np.array([0.5,-0.25,0,0.5,-0.25])\n",
    "test_data = gendata_Deep(500, 0.5,pat=3)\n",
    "\n",
    "set_seed(1194)\n",
    "\n",
    "val_data = gendata_Deep(100, 0.5,pat=3)\n",
    "train_data = gendata_Deep(400, 0.5,pat=3)\n",
    "St = g_dnn_bin(train_data, val_data, test_data, t_nodes, t_fig, s_k, n_layer, n_node, n_lr, n_epoch, patiences)\n",
    "S_R_X_ibs = St['S_R_X_untreat']\n",
    "S_R_X_ibs1 = St['S_R_X_treated']\n",
    "Lambda_R_X_untreat = St['Lambda_R_X_untreat']\n",
    "Lambda_R_X_treated = St['Lambda_R_X_treated']\n",
    "Cmean_R_X_untreat = St['Cmean_R_X_untreat']\n",
    "Cmean_R_X_treated = St['Cmean_R_X_treated']\n",
    "optITR_deep_bin(test_data,Cmean_R_X_treated, Cmean_R_X_untreat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     19\u001b[39m     inti = \u001b[38;5;28mint\u001b[39m(i)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     epsilon[inti] = np.random.normal(n, \u001b[32m0\u001b[39m, (X[inti]**\u001b[32m2\u001b[39m+\u001b[32m0.5\u001b[39m))\n\u001b[32m     21\u001b[39m epsilon = np.clip(epsilon, -\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#baseline mu0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:1576\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.normal\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_common.pyx:657\u001b[39m, in \u001b[36mnumpy.random._common.cont\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "corr = 0.5\n",
    "A = ndm.binomial(1, 0.5, n) #parametric\n",
    "A = np.vstack((A,1-A))\n",
    "\n",
    "#parametric X\n",
    "mean = np.zeros(5)\n",
    "cov = np.identity(5)*(1-corr) + np.ones((5, 5))*corr\n",
    "X = np.random.multivariate_normal(mean,cov,n)\n",
    "X = np.clip(X, -1, 1) #t-distributed with [-1,1]\n",
    "#A=0, influence g_X\n",
    "g_X = np.cos(X[:,0]**2+2*X[:,1]**2+X[:,2]**3+np.sqrt(X[:,3]+1)*np.log(X[:,4]+2)/20)\n",
    "#A=1, influence h_X\n",
    "h_X = np.sin(X[:,0]/3 + np.exp(X[:,1])/4 + np.cos(X[:,2]* X[:,3])-(np.log(X[:,4]+2)) -0.45)\n",
    "X_quality = np.vstack((g_X , h_X))  #For A=0 and A=1\n",
    "#error epsilon: mixture of Guassian\n",
    "variances = X**2 + 0.5\n",
    "epsilon = np.random.normal(loc = 0, )\n",
    "epsilon = np.clip(epsilon, -1, 1)\n",
    "\n",
    "#baseline mu0\n",
    "mu0 = np.zeros(n)\n",
    "# mu0 = 0.5 + 0.25*X[:,0] *X[:,1] +np.exp(X[:,2])/5 -np.sqrt(X[:,3]+1)*np.log(X[:,4]+2)\n",
    "# mu0 = -0.5 + 0.25*X[:,0] *X[:,1]+np.sin(X[:,2])/3-np.cos(X[:,3]*np.log(X[:,4]+2))/2\n",
    "\n",
    "#Reward R\n",
    "R = np.exp(mu0+(X_quality*A).sum(axis=0)+epsilon) #log R=beta*X+gamma*X*A+epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500.]\n"
     ]
    }
   ],
   "source": [
    "sigma = 1\n",
    "epsilon = np.random.normal(500, 0, sigma)\n",
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.          0.06807265  0.16875492 -0.77146965  0.41553584  0.6591175\n",
      " -0.36771613 -0.315107   -0.09258126  1.         -0.01948264  0.34619635\n",
      "  0.97104555 -1.         -0.9998392   0.5602809   0.34345806  0.8130741\n",
      "  0.60137135  0.29141608 -0.7729462   0.16534916 -0.53028274 -0.57928365\n",
      "  0.44995156 -0.48624814 -0.7617674   0.75760704 -0.5237746  -1.\n",
      " -0.64329356  0.09119519 -0.3980285   0.9635538  -0.19120443  0.03198072\n",
      "  0.9603355   1.          0.35894927  1.          0.65349925  1.\n",
      "  1.         -0.24034639  0.31815937  0.06730147 -0.27024823  1.\n",
      " -0.5317779   1.         -1.          1.         -0.3983254   0.2069471\n",
      "  0.97319025 -0.71385914 -0.19343834  0.37971422 -1.          0.01373778\n",
      " -0.11094785  0.12608325 -0.23058541  0.65736264 -1.          1.\n",
      " -0.0069254  -1.          1.          1.         -0.48328853 -1.\n",
      " -1.         -0.01169717  0.24810006 -0.45120198  0.61939555  0.7983712\n",
      " -1.         -0.3626076   0.19296928  0.5033795   1.          0.79225045\n",
      "  0.2185411  -0.00349116 -1.          0.9849941   0.40818796  0.49635977\n",
      " -1.         -0.22881116  1.         -0.26250076 -1.         -0.47521377\n",
      " -1.         -0.08879209  1.          0.6786005   1.          0.77212775\n",
      " -0.94605654  1.         -1.         -1.         -0.8074507   0.04095152\n",
      " -0.17368022 -0.00776973 -1.          0.4964144   0.529308    0.12053142\n",
      "  0.7913168  -0.7707244  -0.5454395   0.70564085  0.15542881 -0.38327333\n",
      " -0.14662458 -0.1497871   0.25745475 -1.          1.         -0.69330025\n",
      "  0.3905855   0.06987708  1.         -1.          0.46923062 -0.87027043\n",
      " -0.19985025 -0.6445072  -1.         -0.1366847   0.14564964 -0.13099888\n",
      "  0.10896049  0.3035978   0.8195924   0.91585463  0.26428142  0.16487277\n",
      "  1.         -0.5891082   0.21766764  0.22418576 -1.         -0.09768663\n",
      "  0.32252717 -0.03299139  1.          0.7723556   1.         -1.\n",
      "  1.         -1.         -0.33100626  1.          0.00913509 -0.5135217\n",
      "  0.1798694  -0.4431141   0.9070724   0.75183713  0.22326529 -0.48925155\n",
      " -1.         -0.9013966   1.         -0.34290344  1.         -0.50630945\n",
      " -0.365928    1.          1.         -0.30882573  1.          0.06908302\n",
      "  1.          1.          0.3312429   0.16726325  0.5971826   0.8874782\n",
      "  1.          0.3511607  -1.          0.84888107 -0.98265344 -0.7639895\n",
      " -1.         -0.13429128 -0.43753943  0.5228668   0.7808141   1.\n",
      "  1.          0.24188429  0.0632136   1.         -0.8475435  -0.54645926\n",
      "  0.20754676  0.83665574  0.7834137  -1.         -1.          0.3452878\n",
      " -0.06015926 -0.7715922   1.         -0.56785756 -1.          1.\n",
      "  0.18863901  0.80968016 -0.66099226  0.6193635   0.03703348 -1.\n",
      " -1.          0.59586746 -1.          1.         -1.         -1.\n",
      " -1.          0.7096617  -0.18965736 -0.37359253  1.         -0.00354392\n",
      "  0.49337426 -0.11808576  1.         -0.47110814 -0.1800246  -0.6656947\n",
      "  0.46036378 -0.7086384  -0.31643417 -0.6977795   0.43041497 -0.61082906\n",
      "  0.5507316  -1.          1.         -0.08299042 -0.7465169   0.62942755\n",
      "  1.         -0.33621827 -0.70116466 -0.9961327  -0.06406114 -1.\n",
      "  0.20347081  0.08869225  0.37207165 -1.          1.         -0.91699463\n",
      " -1.         -1.         -0.8058551   0.08781561  0.5453429  -0.9342542\n",
      " -1.          0.7954142  -1.          0.13141075 -0.08872832 -0.40616328\n",
      "  1.         -1.          1.         -0.7954638  -0.9447498   0.06518938\n",
      "  1.          1.          0.09400459  0.6005789   1.         -0.37051776\n",
      "  0.90917635 -0.78409994  0.592062    0.52546895  0.0609795   1.\n",
      "  1.         -0.8796995   0.87754554 -0.7618037   0.2600088   0.90456736\n",
      " -1.         -1.         -0.32501292 -0.04724575  1.          0.41286337\n",
      " -0.26518342  0.3427714  -1.          0.19999483 -1.          0.75746566\n",
      " -0.5099083   1.         -1.         -1.         -1.          1.\n",
      "  1.          0.31173256 -1.         -0.44156876  1.         -1.\n",
      " -0.13620242  0.5589911   0.7088243   0.3625552  -0.3391169   0.7863221\n",
      "  0.98687786  1.         -0.32413128 -1.         -0.4850515  -0.30009136\n",
      "  0.5541933  -0.92093086  0.5932975  -0.61860526 -0.00847524  0.43280452\n",
      " -0.10987689 -0.6636731  -0.40479565  0.33178693  0.26684746 -0.04248456\n",
      " -1.          0.14462002  0.6474769   0.22870013  1.          0.43289912\n",
      "  1.          1.         -1.          0.37628075  1.          1.\n",
      "  0.89430916  1.         -1.         -1.          0.6349682   1.\n",
      "  0.9636314  -0.89292365 -0.71332276  0.24784012 -1.          0.19488752\n",
      "  0.8565493  -0.61775374 -0.1738541  -1.          0.35417423 -0.25655973\n",
      " -0.7504953   0.83119106 -0.3419888  -1.         -0.46912298 -0.26352674\n",
      "  1.         -0.2532392  -0.8980228   0.32408762  0.36330307  1.\n",
      " -0.7564269   1.         -0.33430243  0.5919896  -0.14353584 -0.7797091\n",
      "  0.54488266  1.          0.20171654  0.6949815   0.70042044  1.\n",
      "  1.          1.          1.         -1.          0.9982679  -0.5892383\n",
      "  0.6971179  -0.7757497   1.          0.02575629 -0.05078581 -1.\n",
      "  0.6128469   0.5374929   1.         -0.96345973  1.          0.57721764\n",
      " -0.62193364  0.39086464  1.         -1.         -1.          0.91828966\n",
      "  1.         -0.5709113   0.3810459   0.64906025  0.10452144  1.\n",
      " -1.         -1.         -0.14320552 -1.          0.6738523   1.\n",
      " -0.824447    0.84946615  1.          0.22772126 -0.18395896 -1.\n",
      "  0.7403439  -0.90611273 -1.          0.20269947 -0.5759756   0.49541497\n",
      " -0.09551147  1.         -0.35077563  1.          1.         -1.\n",
      " -0.28531355 -0.23412333 -0.31281477  0.63245285  1.         -0.39507025\n",
      "  1.          0.05051222  0.70985764 -1.          1.         -1.\n",
      " -0.04186431  0.71614707  0.89771426  0.3114754  -0.66578525  0.6715844\n",
      " -0.5869195   0.07026988 -0.01909162 -1.          0.67548156  0.82448995\n",
      " -0.07930692 -0.12534748 -0.73006374 -0.8774956   0.36955607  1.\n",
      "  1.          0.7974771   1.          1.         -0.35986763  0.50540906\n",
      "  0.67306644  0.37316313  0.04229311  1.          0.30349585  0.25986698\n",
      " -0.42739746 -0.8635059 ]\n"
     ]
    }
   ],
   "source": [
    "beta = np.array([0,-0.5,0.5,-0.25,0.5])\n",
    "gamma = np.array([0.5,-0.25,0,0.5,-0.25])\n",
    "test_data = gendata_Linear(500, 0.5,beta,gamma)\n",
    "print(test_data['epsilon'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
